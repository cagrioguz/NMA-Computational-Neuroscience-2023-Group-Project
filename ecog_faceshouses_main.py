# -*- coding: utf-8 -*-
"""ECoG_faceshouses_Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HLZNgA_lbf1IWbUy44aB0ybZXbrWRUoS

# <strong><font color=#A52A2A></span> Loading of Miller ECoG data of faces/houses (+ noise) </strong>

## SOS team

Sara Azarnoush

Osman Cagri Oguz

sungje Kim

# <font color='red'> Table of content
-------

- Requirements
    - Data retrieval
    - Install and Import
  - Data
    - Data info
    - Data loader
  - Channels in each subject
    - Number of channels in each subj
    - Functions
    - Summary
    - Channels
      - Sbj 0
      - Sbj 1
      - Sbj 2
      - Sbj 3
      - Sbj 4
      - Sbj 5
      - Sbj 6
  - Linear Regression Model
    - Functions
    - Channels
  - Linear Regression Model Novelty
      - Functions
      - Channels
  - Decision Tree Regressor Model
      - Functions
      - Channels
  - Decision Tree Regressor Model Novelty
      - Functions
      - Channels
  - Compare Predicted
      - Functions
      - Channels
  - SVR
      - Functions
      - Channels

# <font color='red'> Requirements
-------

## <font color='green'>Data retrieval
"""

import os, requests

fname = 'faceshouses.npz'
url = "https://osf.io/argh7/download"

if not os.path.isfile(fname):
  try:
    r = requests.get(url)
  except requests.ConnectionError:
    print("!!! Failed to download data !!!")
  else:
    if r.status_code != requests.codes.ok:
      print("!!! Failed to download data !!!")
    else:
      with open(fname, "wb") as fid:
        fid.write(r.content)

"""## <font color='green'> Install and Import

Install packages (`nilearn`, `nimare`), import `matplotlib` and set defaults
"""

# install packages to visualize brains and electrode locations
!pip install nilearn --quiet
!pip install nimare --quiet

from matplotlib import rcParams
from matplotlib import pyplot as plt
rcParams['figure.figsize'] = [20, 4]
rcParams['font.size'] = 15
rcParams['axes.spines.top'] = False
rcParams['axes.spines.right'] = False
rcParams['figure.autolayout'] = True

import numpy as np
from scipy import signal
from sklearn.linear_model import LinearRegression
from scipy.stats import ttest_rel
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

"""# <font color='red'> Data
-------

## <font color='green'> Dataset info

This is one of multiple ECoG datasets from Miller 2019, recorded in a clinical settings with a variety of tasks. We plan to curate a few more before NMA starts. Raw data here:

https://exhibits.stanford.edu/data/catalog/zk881ps0522

`alldat` contains 7 subjects each with two sessions `dat1` and `dat2`, and was originally used in these publications:

*Miller, Kai J., et al. "Face percept formation in human ventral temporal cortex." Journal of neurophysiology 118.5 (2017): 2614-2627.*

*Miller, Kai J., et al. "The physiology of perception in human temporal lobe is specialized for contextual novelty." Journal of neurophysiology 114.1 (2015): 256-263.*

*Miller, Kai J., et al. "Spontaneous decoding of the timing and content of human object perception from cortical surface recordings reveals complementary information in the event-related potential and broadband spectral change." PLoS computational biology 12.1 (2016): e1004660.*

*Miller, Kai J., et al. "The physiology of perception in human temporal lobe is specialized for contextual novelty." Journal of neurophysiology 114.1 (2015): 256-263.*

*Miller, Kai J., et al. "Spontaneous decoding of the timing and content of human object perception from cortical surface recordings reveals complementary information in the event-related potential and broadband spectral change." PLoS computational biology 12.1 (2016): e1004660.*

In this task, subjects in a clinical settings (with ECoG implants) are passively shown faces and house during the first experiment (`dat1`). Then in the second experiment in the same subjects (`dat2`), noise is added to face and houses images and the subject has to detect the faces by pressing a key. Two of the subjects don't have keypresses.

Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across time and conversion to float16 to minimize size.

Experiment 1:
* `dat1['V']`: continuous voltage data (time by channels)
* `dat1['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  
* `dat1['t_on']`: time of stimulus onset in data samples
* `dat1['t_off']`: time of stimulus offset, always 400 samples after `t_on`
* `dat1['stim_id`]: identity of stimulus from 1-100, with 1-50 being houses and 51-100 being faces
* `dat1['locs`]: 3D electrode positions on the brain surface

Experiment 2:
* `dat2['V`]: continuous voltage data (time by channels)
* `dat2['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  
* `dat2['t_on']`: time of stimulus onset in data samples
* `dat2['t_off']`: time of stimulus offset, always 1000 samples after `t_on`, with no inter-stimulus interval
* `dat2['stim_id`]: identity of stimulus from 1-600 (not really useful, since we don't know which ones are the same house/face)
* `dat2['stim_cat']`: stimulus category (1 = house, 2 = face)
* `dat2['stim_noise']`: percent noise from 0 to 100
* `dat2['key_press']`: when the subject thought the image was a face
* `dat2['categories']`: categories legend (1 = house, 2 = face)
* `dat2['locs`]: 3D electrode positions on the brain surface

## <font color='green'> Data loading
"""

alldat = np.load(fname, allow_pickle=True)['dat']

"""# <font color='red'> Channels in each subject
-------

## <font color='green'>  number of channels in each subj
"""

for subject in range(7):
  V = alldat[subject][0]['V']
  print(V.shape)

for subject in range(7):
  V = alldat[subject][1]['V']
  print(V.shape)

"""## <font color='green'>  Functions"""

from nilearn import plotting
from nimare import utils

def show_channels(iSubj):
  plt.figure(figsize=(8, 8))
  locs = alldat[iSubj][1]['locs']
  view = plotting.view_markers(utils.tal2mni(locs),
                              marker_labels=['%d'%k for k in np.arange(locs.shape[0])],
                              marker_color='purple',
                              marker_size=5)
  return view

# quick way to get broadband power in time-varying windows
from scipy import signal
import math

def draw_allchannelresp_exp1(iSubj):
  dat1 = alldat[iSubj][0]
  V = dat1['V'].astype('float32')

  b, a = signal.butter(3, [50], btype='high', fs=1000)
  V = signal.filtfilt(b, a, V, 0)
  V = np.abs(V)**2
  b, a = signal.butter(3, [10], btype='low', fs=1000)
  V = signal.filtfilt(b, a, V, 0)

  V = V/V.mean(0)

  # average the broadband power across all face stimuli and across all house stimuli

  nt, nchan = V.shape
  nstim = len(dat1['t_on'])

  trange = np.arange(-200, 400)
  ts = dat1['t_on'][:, np.newaxis] + trange
  V_epochs = np.reshape(V[ts, :], (nstim, 600, nchan))

  V_house = (V_epochs[dat1['stim_id'] <= 50]).mean(0)
  V_face = (V_epochs[dat1['stim_id'] > 50]).mean(0)
  print(len(V_face[0,:])) #--> 600x50
  print("Parameters for dat1:",len(trange),len(ts),nstim)

  nCh = V.shape[1]

  # let's find the electrodes that distinguish faces from houses
  plt.figure(figsize=(20, 10))
  for j in range(nCh):
    ax = plt.subplot(math.ceil(nCh/10), math.ceil(nCh/math.ceil(nCh/10)), j+1)
    plt.plot(trange, V_house[:, j], label='house')
    plt.plot(trange, V_face[:, j],label='face')
    plt.title('ch%d'%j)
    plt.xticks([-200, 0, 200])
    plt.ylim([0, 4])
    if j ==0:
      plt.legend()
  plt.show()

def draw_allchannelresp_exp2(iSubj):
  dat2 = alldat[iSubj][1]
  V2 = dat2['V'].astype('float32')

  b, a = signal.butter(3, [50], btype='high', fs=1000)
  V2 = signal.filtfilt(b, a, V2, 0)
  V2 = np.abs(V2)**2
  b, a = signal.butter(3, [10], btype='low', fs=1000)
  V2 = signal.filtfilt(b, a, V2, 0)

  V2 = V2/V2.mean(0)

  # average the broadband power across all face stimuli and across all house stimuli

  nt2, nchan2 = V2.shape
  nstim2 = len(dat2['t_on'])
  trange2 = np.arange(-200,1000)
  ts2 = dat2['t_on'][:, np.newaxis] + trange2
  V2_epochs = np.reshape(V2[ts2, :], (nstim2, 1200, nchan2))
  temp = np.squeeze(dat2['stim_cat'])
  V2_house = (V2_epochs[temp == 1]).mean(0)
  V2_face = (V2_epochs[temp == 2]).mean(0)
  print(len(V2_face[0,:])) #--> 600x50
  print("Parameters for dat2:",len(trange2),len(ts2),nstim2)

  nCh = V2.shape[1]

  # let's find the electrodes that distinguish faces from houses
  plt.figure(figsize=(20, 10))
  #plt.title("Data for 2nd Experiment")
  for j in range(nCh):
    ax = plt.subplot(math.ceil(nCh/10), math.ceil(nCh/math.ceil(nCh/10)), j+1)
    plt.plot(trange2, V2_house[:, j], label='house')
    plt.plot(trange2, V2_face[:, j],label='face')
    plt.title('ch%d'%j)
    plt.xticks(np.arange(-200, 1200, 200))
    plt.xticks(rotation=-45)
    plt.ylim([0, 4])
    if j ==0:
      plt.legend()
  plt.show()

"""## <font color='green'>  Summary"""

'''
Here is the summary of each subj's face and house selective channel
Subj 0, face: ch 35 house: none
Subj 1, face: 46 47 house: none
Subj 2, face: 35 house: none
Subj 3, face: 23 house: none
Subj 4, face: none house: none
Subj 5, face: 30 house: none
Subj 6, face: none house: none
'''

print(alldat[0][0]['locs'][35,:])
print(alldat[1][0]['locs'][46,:])
print(alldat[1][0]['locs'][47,:])
print(alldat[2][0]['locs'][35,:])
print(alldat[3][0]['locs'][23,:])
print(alldat[5][0]['locs'][30,:])
plt.figure(figsize=(8, 8))
locs = alldat[0][0]['locs'][35,:]
locs = np.vstack([locs, alldat[1][0]['locs'][46,:]])
locs = np.vstack([locs, alldat[1][0]['locs'][47,:]])
locs = np.vstack([locs, alldat[2][0]['locs'][35,:]])
locs = np.vstack([locs, alldat[3][0]['locs'][23,:]])
locs = np.vstack([locs, alldat[5][0]['locs'][30,:]])
# print(locs)
view = plotting.view_markers(utils.tal2mni(locs),
                            marker_labels=['%d'%k for k in np.arange(locs.shape[0])],
                            marker_color='purple',
                            marker_size=5)
view

"""## <font color='green'> Subjects

### <font color='blue'>  Subj 0, face: 35 house: none
"""

# iSubj=0, 41 channels, but only channel 35 are response to face, no house selective channels
iSubj = 0
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(0)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 1, face: 46 47 house: none"""

# iSubj=1, 50 channels, but only channel 46 47 are response to face, no house selective channels
iSubj = 1
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 2, face: 35 house: none"""

# iSubj=2, 39 channels, but only channel 35 are response to face, no house selective channels
iSubj = 2
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 3, face: 23 house: none"""

# iSubj=3, 60 channels, but only channel 23 are response to face, no house selective channels
iSubj = 3
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 4, face: none house: none Warning: its channel position is ruined..."""

# iSubj=4, 58 channels, but no face, house selective channels, also its position is ruined...
iSubj = 4
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 5, face: 30 house: none"""

# iSubj=5, 39 channels, but only channel 30 are response to face, no house selective channels
iSubj = 5
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""### <font color='blue'> Subj 6, face: none house: none"""

# iSubj=6, 58 channels, but no face, house selective channels
iSubj = 6
print(np.unique(alldat[iSubj][0]['lobe'])) # lobe of electrode's location
view = show_channels(iSubj)
view

draw_allchannelresp_exp1(iSubj)

draw_allchannelresp_exp2(iSubj)

"""# <font color='red'> Data separation
-------

## <font color='green'> Data
"""

def data_sepration (dat1, dat2):

    V = dat1['V'].astype('float32')
    b, a = signal.butter(3, [50], btype='high', fs=1000)
    V = signal.filtfilt(b, a, V, 0)
    V = np.abs(V)**2
    b, a = signal.butter(3, [10], btype='low', fs=1000)
    V = signal.filtfilt(b, a, V, 0)

    V = V/V.mean(0)
    V2 = dat2['V'].astype('float32')
    b, a = signal.butter(3, [50], btype='high', fs=1000)
    V2 = signal.filtfilt(b, a, V2, 0)
    V2 = np.abs(V2)**2
    b, a = signal.butter(3, [10], btype='low', fs=1000)
    V2 = signal.filtfilt(b, a, V2, 0)

    V2 = V2/V2.mean(0)
    nt, nchan = V.shape
    nstim = len(dat1['t_on'])

    trange = np.arange(-200, 400)
    ts = dat1['t_on'][:, np.newaxis] + trange
    V_epochs = np.reshape(V[ts, :], (nstim, 600, nchan))
    #print(V_epochs.shape)
    V_house = (V_epochs[dat1['stim_id'] <= 50]).mean(0)
    V_face = (V_epochs[dat1['stim_id'] > 50]).mean(0)
    print("face ", len(V_face[0,:])) #--> 600x50
    print("Parameters for dat1:",len(trange),len(ts),nstim)

    nt2, nchan2 = V2.shape
    nstim2 = len(dat2['t_on'])
    trange2 = np.arange(-200,1000)
    ts2 = dat2['t_on'][:, np.newaxis] + trange2
    print("Parameters for dat2:",len(trange2),len(ts2),nstim2)
    V2_epochs = np.reshape(V2[ts2, :], (nstim2, 1200, nchan2))
    temp = np.squeeze(dat2['stim_cat'])
    V2_house = (V2_epochs[temp == 1]).mean(0)
    V2_face = (V2_epochs[temp == 2]).mean(0)

    ind_houseface1 = []
    ind_facehouse1 = []
    ind_faceface1 = []
    ind_househouse1 = []
    for i in range(299):
      if dat1['stim_id'][i] <= 50 and dat1['stim_id'][i+1] > 50:
        ind_houseface1.append(i+1)
      elif dat1['stim_id'][i] <= 50 and dat1['stim_id'][i+1] <= 50:
        ind_househouse1.append(i+1)
      elif dat1['stim_id'][i] > 50 and dat1['stim_id'][i+1] > 50:
        ind_faceface1.append(i+1)
      else:
        ind_facehouse1.append(i+1)

    ind_houseface2 = []
    ind = [0]
    ind_facehouse2 = []
    ind_faceface2 = []
    ind_househouse2 = []

    for i in range(629):
      if dat2['stim_cat'][i] == 1 and dat2['stim_cat'][i+1] == 2:
        ind_houseface2.append(i+1)
        ind.append(2)
      elif dat2['stim_cat'][i] == 1 and dat2['stim_cat'][i+1] == 1:
        ind_househouse2.append(i+1)
        ind.append(1)
      elif dat2['stim_cat'][i] == 2 and dat2['stim_cat'][i+1] == 2:
        ind_faceface2.append(i+1)
        ind.append(1)
      else:
        ind_facehouse2.append(i+1)
        ind.append(2)
    # print(np.sum(ind))
    # print(len(ind))

    noise = []
    for i in range(630):
      for value in dat2['stim_noise'][i]:
        #print(value)
        noise.append(value)
    category = []
    for i in range(630):
      for value in dat2['stim_cat'][i]:
        #print(value)
        category.append(value)
    dat2['novelty'] = ind
    dat2['noise_level'] = noise
    dat2['category'] = category
    print("data 2 noise level lenght: ", len(dat2['noise_level']))
    print("data 2 novelty sum: ", sum(dat2['novelty']))
    print("data 2 catagory lenght: ", len(dat2['category']))

    y = V2_face[200:600]
    avg_activity = V_face[200:]

    # Create a list of all the unique noise levels
    noise_levels = np.unique(dat2['noise_level'])
    num = np.zeros(21)
    indices_noise = []
    i = 0
    for n in noise_levels:
      for x in range(len(dat2['noise_level'])):
        if dat2['noise_level'][x] == n:
          num[i]+=1
          indices_noise.append(x)
      i += 1
    # print(indices_noise)
    numint = []
    for x in range(len(num)):
      numint.append(int(num[x]))
    # print(numint)
    a=[]
    b=[]
    suma = []
    sumb = []
    u = 0
    for i in numint:
      for j in indices_noise[u:u+i]:
        a.append(dat2['category'][j])
        b.append(dat2['novelty'][j])
      suma.append(sum(a)-sum(suma))
      sumb.append(sum(b)-sum(sumb))
      u = u + i
    # print(suma)
    # print(sumb)
    # print(i)

    # Iterate over the noise levels
    u = 0
    #noise 0: 15 - 15 --> 7+8 - 8+7 except for noise level 10: 8+7 - 9+8 and noise level 100: 7+8 - 6+7 -> 315 - 315 if we divide by category and noise
    noveltyhousenoisecat = []
    noveltyfacenoisecat = []
    sumnhnc = []
    sumnfnc = []
    for i in numint:
      for j in indices_noise[u:u+i]:
        if dat2['category'][j] == 1:
          noveltyhousenoisecat.append(dat2['novelty'][j])
        else:
          noveltyfacenoisecat.append(dat2['novelty'][j])
      sumnhnc.append(sum(noveltyhousenoisecat)-sum(sumnhnc))
      sumnfnc.append(sum(noveltyfacenoisecat)-sum(sumnfnc))
      u = u + i
    # print(sumnhnc)
    # print(sumnfnc)

    return numint, indices_noise, V2_epochs

"""#noise 0: 7 house (4novel) + 8 face(4novel) - 8 house (4 novel) + 7 face (3 novel)
    #noise 5: 7 house (4novel) + 8 face(2novel) - 8 house (4 novel) + 7 face(1 novel)
    #noise 10: 8 house (5 novel) + 7 face(6 novel) - 9 house (5 novel) + 8 face (7 novel)
    #noise 15: 7 house(3 novel) + 8 face(4 novel) - 8 house(4 novel) + 7 face(3 novel)
    #noise 20: 7 house(3 novel) + 8 face(4 novel) - 8 house(4 novel) + 7 face(3 novel)
    #noise 25: 7 house(3 novel) + 8 face(4 novel) - 8 house(3 novel) + 7 face(4 novel)
    #noise 30: 7 house(3 novel) + 8 face(3 novel) - 8 house(3 novel) + 7 face(3 novel)
    #noise 35: 7 house(4 novel) + 8 face(5 novel) - 8 house(4 novel) + 7 face(4 novel)
    #noise 40: 7 house(2 novel) + 8 face(6 novel) - 8 house(2 novel) + 7 face(6 novel)
    #noise 45: 7 house(5 novel) + 8 face(2 novel) - 8 house(5 novel) + 7 face(2 novel)
    #noise 50: 7 house(3 novel) + 8 face(4 novel) - 8 house(3 novel) + 7 face(4 novel)
    #noise 55: 7 house(4 novel) + 8 face(4 novel) - 8 house(5 novel) + 7 face(3 novel)
    #noise 60: 7 house(3 novel) + 8 face(2 novel) - 8 house(4 novel) + 7 face(2 novel)
    #noise 65: 7 house(5 novel) + 8 face(4 novel) - 8 house(5 novel) + 7 face(4 novel)
    #noise 70: 7 house(2 novel) + 8 face(5 novel) - 8 house(3 novel) + 7 face(4 novel)
    #noise 75: 7 house(5 novel) + 8 face(6 novel) - 8 house(6 novel) + 7 face(5 novel)
    #noise 80: 7 house(6 novel) + 8 face(3 novel) - 8 house(6 novel) + 7 face(3 novel)
    #noise 85: 7 house(4 novel) + 8 face(5 novel) - 8 house(5 novel) + 7 face(4 novel)
    #noise 90: 7 house(3 novel) + 8 face(6 novel) - 8 house(4 novel) + 7 face(5 novel)
    #noise 95: 7 house(5 novel) + 8 face(6 novel) - 8 house(6 novel) + 7 face(5 novel)
    #noise 100: 7 house(3 novel) + 8 face(4 novel) - 8 house(4 novel) + 7 face(4 novel)
    #train: 168 test: 168

## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

dat1 = alldat[0][0]
dat2 = alldat[0][1]

numint1, indices_noise1, V2_epochs1  = data_sepration(dat1, dat2)

"""### <font color='blue'> Subj 1"""

dat1 = alldat[1][0]
dat2 = alldat[1][1]

numint2, indices_noise2, V2_epochs2  = data_sepration(dat1, dat2)

"""### <font color='blue'> Subj 2"""

dat1 = alldat[2][0]
dat2 = alldat[2][1]

numint3, indices_noise3, V2_epochs3  = data_sepration(dat1, dat2)

"""### <font color='blue'> Subj 3"""

dat1 = alldat[3][0]
dat2 = alldat[3][1]

numint4, indices_noise4, V2_epochs4  = data_sepration(dat1, dat2)

"""### <font color='blue'> Subj 5"""

dat1 = alldat[5][0]
dat2 = alldat[5][1]

numint6, indices_noise6, V2_epochs6  = data_sepration(dat1, dat2)

"""# <font color='red'> Linear Regression Model
-------

## <font color='green'> Linear Regression Model
"""

def lr_modeling(fs_elec, numint, indices_noise, V2_epochs, dat1, dat2):

    facenovel = [4,2,6,4,4,4,3,5,6,2,4,4,2,4,5,6,3,5,6,6,4]
    facerepea = [4,6,1,4,4,4,5,3,2,6,4,4,6,4,3,2,5,3,2,2,4]
    housenove = [4,4,5,3,3,3,3,4,2,5,3,4,3,5,2,5,6,4,3,5,3]
    houserepe = [3,3,3,4,4,4,4,3,5,2,4,3,4,2,5,2,1,3,4,2,4]
    traini = []
    testi = []
    a = 0
    x = 0
    y = 0
    z = 0
    t = 0
    u = 0

    #Creating two lists containing the trial number for train and test dataset
    for i in numint:
      for j in indices_noise[u:u+i]:
        if (dat2['category'][j]) == 2 and (dat2['novelty'][j] == 2) and (z < facenovel[a]):
          traini.append(j)
          z+=1
        elif (dat2['category'][j] == 2) and (dat2['novelty'][j] == 1) and (t < facerepea[a]):
          traini.append(j)
          t+=1
        elif dat2['category'][j] == 2:
          testi.append(j)
      z = 0
      t = 0
      a+=1
      u=u+i

    #Creating the feature and target vectors for the train dataset
    yavg_train = []
    x_novel = []
    x_noise = []
    x_cat = []
    fs_elec = fs_elec
    # print(len(traini))

    for i in traini:
      yavg_train.append(V2_epochs[i,200:600,fs_elec].mean())
      x_novel.append(dat2['novelty'][i]-1)
      x_noise.append(dat2['noise_level'][i]/100)
      x_cat.append(i)

    x_cat = np.reshape(x_cat, (len(traini), 1))
    x_novel = np.reshape(x_novel, (len(traini), 1))
    x_noise = np.reshape(x_noise, (len(traini), 1))
    x_train = np.concatenate([x_novel, x_noise], axis=1)

    #Creating the feature and target vectors for the test dataset
    yavg_test = []
    x_novelt = []
    x_noiset = []
    x_catt = []

    for i in testi:
      yavg_test.append(V2_epochs[i,200:600,fs_elec].mean())
      x_novelt.append(dat2['novelty'][i]-1)
      x_noiset.append(dat2['noise_level'][i]/100)
      x_catt.append(i)
    x_catt = np.reshape(x_catt, (len(testi), 1))
    x_novelt = np.reshape(x_novelt, (len(testi), 1))
    x_noiset = np.reshape(x_noiset, (len(testi), 1))
    x_test = np.concatenate([x_novelt, x_noiset], axis=1)

    #Using a Linear Regression Model
    model = LinearRegression()
    #Training the model with train feature and target vectors
    model.fit(x_train, yavg_train)
    #Predictions of the model for the test dataset
    y_pred = model.predict(x_test)

    mse = np.mean((yavg_test - y_pred)**2)
    print("mse: ", mse)

    # Plot the real observations
    plt.plot(yavg_test, 'bo', label='Real Observations')
    # Plot the predicted values
    plt.plot(y_pred, 'ro', label='Predicted Values')
    # Add a title to the plot
    plt.title('Linear Regression Model')
    # Add labels to the axes
    plt.xlabel('x')
    plt.ylabel('y')
    # Show the plot
    plt.show()
    coefficients = model.coef_

    # print("coefficients: ", coefficients)
    # print(x_test[0],x_test[1],x_test[2])
    # print(yavg_test[14])

    return x_train, x_test, yavg_train, yavg_test, mse, y_pred

"""## <font color='green'> Channel

### <font color='blue'> Subj 0
"""

dat1 = alldat[0][0]
dat2 = alldat[0][1]

fs_elec = 35

x_train1, x_test1, yavg_train1, yavg_test1, mse1, y_pred1 = lr_modeling(fs_elec, numint1, indices_noise1, V2_epochs1, dat1, dat2)

"""### <font color='blue'> Subj 1"""

dat1 = alldat[1][0]
dat2 = alldat[1][1]
fs_elec = 46

x_train2, x_test2, yavg_train2, yavg_test2, mse2, y_pred2 = lr_modeling(fs_elec, numint2, indices_noise2, V2_epochs2, dat1, dat2)

"""### <font color='blue'> Subj 2"""

dat1 = alldat[2][0]
dat2 = alldat[2][1]

fs_elec = 35

x_train3, x_test3, yavg_train3, yavg_test3, mse3, y_pred3 = lr_modeling(fs_elec, numint3, indices_noise3, V2_epochs3, dat1, dat2)

"""### <font color='blue'> Subj 3"""

dat1 = alldat[3][0]
dat2 = alldat[3][1]
fs_elec = 23

x_train4, x_test4, yavg_train4, yavg_test4, mse4, y_pred4 = lr_modeling(fs_elec, numint4, indices_noise4, V2_epochs4, dat1, dat2)

"""### <font color='blue'> Subj 5"""

dat1 = alldat[5][0]
dat2 = alldat[5][1]
fs_elec = 30

x_train6, x_test6, yavg_train6, yavg_test6, mse6, y_pred6 = lr_modeling(fs_elec, numint6, indices_noise6, V2_epochs6, dat1, dat2)

"""# <font color='red'> Linear Regression Model Novelty
-------

## <font color='green'> Linear Regression Model Novelty
"""

def lr_modeling_novel(x_train, x_test, yavg_train, yavg_test, mse):

  # Create the feature vector excluding novelty
  x_train_nonovelty = np.delete(x_train,0,axis=1)
  x_test_nonovelty = np.delete(x_test,0,axis=1)
  model = LinearRegression()
  model.fit(x_train_nonovelty, yavg_train)
  y_pred2 = model.predict(x_test_nonovelty)

  # Calculate the MSE value
  mse2 = np.mean((yavg_test - y_pred2)**2)
  print("mse: ", mse2)

  # Plot the real observations
  plt.plot(yavg_test, 'bo', label='Real Observations')
  # Plot the predicted values
  plt.plot(y_pred2, 'ro', label='Predicted Values')
  # Add a title to the plot
  plt.title('Linear Regression Model')
  # Add labels to the axes
  plt.xlabel('x')
  plt.ylabel('y')
  # Show the plot
  plt.show()

  t_test, p_value = ttest_rel(mse, mse2)
  # Print the results of the t-test
  print(f"t-statistic: {t_test}")
  print(f"p-value: {p_value}")

  return x_train_nonovelty, x_test_nonovelty, mse2

"""## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

x_train_nonovelty1, x_test_nonovelty1, mse1n = lr_modeling_novel(x_train1, x_test1, yavg_train1, yavg_test1, mse1)

"""### <font color='blue'> Subj 1"""

x_train_nonovelty2, x_test_nonovelty2, mse2n = lr_modeling_novel(x_train2, x_test2, yavg_train2, yavg_test2, mse2)

"""### <font color='blue'> Subj 2"""

x_train_nonovelty3, x_test_nonovelty3, mse3n = lr_modeling_novel(x_train3, x_test3, yavg_train3, yavg_test3, mse3)

"""### <font color='blue'> Subj 3"""

x_train_nonovelty4, x_test_nonovelty4, mse4n = lr_modeling_novel(x_train4, x_test4, yavg_train4, yavg_test4, mse4)

"""### <font color='blue'> Subj 5"""

x_train_nonovelty6, x_test_nonovelty6, mse6n = lr_modeling_novel(x_train6, x_test6, yavg_train6, yavg_test6, mse6)

mse_lr_novelty = [mse1, mse2, mse3, mse4, mse6]
mse_lr_nonovelty = [mse1n, mse2n, mse3n, mse4n, mse6n]
t_test, p_value = ttest_rel(mse_lr_novelty, mse_lr_nonovelty)
# Print the results of the t-test
print(f"t-statistic: {t_test}")
print(f"p-value: {p_value}")

"""# <font color='red'> Decision Tree Regressor Model
-------

## <font color='green'> Decision Tree Regressor Model
"""

def create_dtr(x_train, x_test, yavg_train, yavg_test):

    # Create the decision tree regressor model
    model = DecisionTreeRegressor()
    # Fit the model to the data
    model.fit(x_train, yavg_train)
    # Predict the values for the test set
    y_pred_dt = model.predict(x_test)

    # Calculate the MSE value
    se = (yavg_test - y_pred_dt)**2
    mse = se.mean()
    # Print the MSE value
    print("mse: ", mse)

    # Plot the real observations
    plt.plot(yavg_test, 'bo', label='Real Observations')
    # Plot the predicted values
    plt.plot(y_pred_dt, 'ro', label='Predicted Values')
    # Add a title to the plot
    plt.title('Decision Tree Model')
    # Add labels to the axes
    plt.xlabel('x')
    plt.ylabel('y')

    # Get the coefficients
    coefficients = model.feature_importances_
    # Print the coefficients
    print("coefficients: ", coefficients)# Show the plot
    plt.show()

    return y_pred_dt, mse

"""## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

y_pred_dt1, mse1dt = create_dtr(x_train1, x_test1, yavg_train1, yavg_test1)

"""### <font color='blue'> Subj 1"""

y_pred_dt2, mse2dt = create_dtr(x_train2, x_test2, yavg_train2, yavg_test2)

"""### <font color='blue'> Subj 2"""

y_pred_dt3, mse3dt = create_dtr(x_train3, x_test3, yavg_train3, yavg_test3)

"""### <font color='blue'> Subj 3"""

y_pred_dt4, mse4dt = create_dtr(x_train4, x_test4, yavg_train4, yavg_test4)

"""### <font color='blue'> Subj 5"""

y_pred_dt6, mse6dt = create_dtr(x_train6, x_test6, yavg_train6, yavg_test6)

"""# <font color='red'> Decision Tree Regressor Model Novelty
-------

## <font color='green'> Decision Tree Regressor Model Novelty
"""

def create_dtr_novel(yavg_train, yavg_test, x_train_nonovelty, x_test_nonovelty, mse):

    # Create the decision tree regressor model
    model = DecisionTreeRegressor()

    # Fit the model to the data
    model.fit(x_train_nonovelty, yavg_train)
    # Predict the values for the test set
    y_pred_dt2 = model.predict(x_test_nonovelty)
    # Calculate the MSE value
    se2 = (yavg_test - y_pred_dt2)**2
    mse2 = se2.mean()
    # Print the MSE value
    print("mse: ", mse2)

    # Plot the real observations
    plt.plot(yavg_test, 'bo', label='Real Observations')
    # Plot the predicted values
    plt.plot(y_pred_dt2, 'ro', label='Predicted Values')
    # Add a title to the plot
    plt.title('Decision Tree Model noise only')
    # Add labels to the axes
    plt.xlabel('x')
    plt.ylabel('y')
    # Get the coefficients
    coefficients = model.feature_importances_
    # Print the coefficients
    print("coefficients: ", coefficients)# Show the plot
    plt.show()

    t_test, p_value = ttest_rel(mse, mse2)
    # Print the results of the t-test
    print(f"t-statistic: {t_test}")
    print(f"p-value: {p_value}")

    return y_pred_dt2, mse2

"""## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

y_pred_dt21, mse1dtn = create_dtr_novel(yavg_train1, yavg_test1, x_train_nonovelty1, x_test_nonovelty1, mse1)

"""### <font color='blue'> Subj 1"""

y_pred_dt22, mse2dtn = create_dtr_novel(yavg_train2, yavg_test2, x_train_nonovelty2, x_test_nonovelty2, mse2)

"""### <font color='blue'> Subj 2"""

y_pred_dt23, mse3dtn = create_dtr_novel(yavg_train3, yavg_test3, x_train_nonovelty3, x_test_nonovelty3, mse3)

"""### <font color='blue'> Subj 3"""

y_pred_dt24, mse4dtn = create_dtr_novel(yavg_train4, yavg_test4, x_train_nonovelty4, x_test_nonovelty4, mse4)

"""### <font color='blue'> Subj 5"""

y_pred_dt26, mse6dtn = create_dtr_novel(yavg_train6, yavg_test6, x_train_nonovelty6, x_test_nonovelty6, mse6)

mse_dt_novelty = [mse1dt, mse2dt, mse3dt, mse4dt, mse6dt]
mse_dt_nonovelty = [mse1dtn, mse2dtn, mse3dtn, mse4dtn, mse6dtn]
t_test_dt, p_value_dt = ttest_rel(mse_dt_novelty, mse_dt_nonovelty)
# Print the results of the t-test
print(f"t-statistic: {t_test_dt}")
print(f"p-value: {p_value_dt}")

"""# <font color='red'> Compare Predicted
-------

## <font color='green'> Plot
"""

mean_lr_novelty = np.mean(mse_lr_novelty)
mean_lr_nonovelty = np.mean(mse_lr_nonovelty)
mean_dt_novelty = np.mean(mse_dt_novelty)
mean_dt_nonovelty = np.mean(mse_dt_nonovelty)
std_lr_novelty = np.std(mse_lr_novelty)/np.sqrt(5)
std_lr_nonovelty = np.std(mse_lr_nonovelty)/np.sqrt(5)
std_dt_novelty = np.std(mse_dt_novelty)/np.sqrt(5)
std_dt_nonovelty = np.std(mse_dt_nonovelty)/np.sqrt(5)
labels = ['LR - novelty', 'LR - no novelty', 'DT - novelty', 'DT - no novelty']
means = [mean_lr_novelty, mean_lr_nonovelty, mean_dt_novelty, mean_dt_nonovelty]
errors = [std_lr_novelty, std_lr_nonovelty, std_dt_novelty, std_dt_nonovelty]

t_test_dtlr, p_value_dtlr = ttest_rel(mse_dt_nonovelty, mse_lr_nonovelty)
# Print the results of the t-test
print(f"t-statistic: {t_test_dtlr}")
print(f"p-value: {p_value_dtlr}")

# Set the positions of the bars on the x-axis
x = np.arange(4)
colors = ['blue', 'blue', 'green', 'green']  # Specify different colors for the last two bars
plt.figure(figsize=(9,6))
plt.bar(labels, means, yerr=errors, color=colors, width = 0.1)


plt.ylabel('Mean MSE')
plt.title('Mean MSE with Error Bars')
plt.ylim(0, 1)
plt.yticks(np.arange(0, 1, 0.2))
plt.xticks(rotation=0)
plt.show()

def plot_dtr(yavg_test, y_pred, y_pred_dt, y_pred_dt2):

    # Plot the real observations
    plt.plot(yavg_test, 'bo', label='Real Observations')

    # Plot the predicted values
    plt.plot(y_pred_dt2, 'r', label='Decision Tree Regressor Predicted Values')
    plt.plot(y_pred_dt, 'x', label='LM odel Novelty Predicted Values')
    plt.plot(y_pred, 'k', label='LM Model Predicted Values')

    # Add a title to the plot
    plt.title('Compare')

"""## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

plot_dtr(yavg_test1, y_pred1, y_pred_dt1, y_pred_dt21)

"""### <font color='blue'> Subj 1"""

plot_dtr(yavg_test2, y_pred2, y_pred_dt2, y_pred_dt22)

"""### <font color='blue'> Subj 2"""

plot_dtr(yavg_test3, y_pred3, y_pred_dt3, y_pred_dt23)

"""### <font color='blue'> Subj 3"""

plot_dtr(yavg_test4, y_pred4, y_pred_dt4, y_pred_dt24)

"""### <font color='blue'> Subj 5"""

plot_dtr(yavg_test6, y_pred6, y_pred_dt6, y_pred_dt26)

"""# <font color='red'> SVR
-------

## <font color='green'> SVR
"""

def svr_model(x_train, x_test, yavg_train, yavg_test, x_train_nonovelty, x_test_nonovelty ):

    # Initialize and fit the SVR model
    svr_model = SVR(kernel='rbf')  # 'rbf' stands for radial basis function kernel
    svr_model.fit(x_train, yavg_train)
    # Predict on the test data
    yavg_pred_svr = svr_model.predict(x_test)
    # Evaluation
    mse_svr = mean_squared_error(yavg_test, yavg_pred_svr)
    r2_svr = r2_score(yavg_test, yavg_pred_svr)
    print("Support Vector Regression - MSE: ", mse_svr)
    print("Support Vector Regression - R^2: ", r2_svr)

    # Initialize and fit the SVR model
    svr_model = SVR(kernel='rbf')  # 'rbf' stands for radial basis function kernel
    svr_model.fit(x_train_nonovelty, yavg_train)
    # Predict on the test data
    yavg_pred_svr = svr_model.predict(x_test_nonovelty)
    # Evaluation
    mse_svr = mean_squared_error(yavg_test, yavg_pred_svr)
    r2_svr = r2_score(yavg_test, yavg_pred_svr)
    print("Support Vector Regression - MSE: ", mse_svr)
    print("Support Vector Regression - R^2: ", r2_svr)

    # Create polynomial features (you can choose the degree)
    degree = 2  # You can experiment with different degrees
    poly_features = PolynomialFeatures(degree=degree)
    x_train_poly = poly_features.fit_transform(x_train)
    x_test_poly = poly_features.transform(x_test)

    # Fit the polynomial regression model
    poly_regression_model = LinearRegression()
    poly_regression_model.fit(x_train_poly, yavg_train)
    # Predict on the test data
    yavg_pred_poly = poly_regression_model.predict(x_test_poly)
    # Evaluation
    mse_poly = mean_squared_error(yavg_test, yavg_pred_poly)
    r2_poly = r2_score(yavg_test, yavg_pred_poly)

    print("Polynomial Regression - MSE: ", mse_poly)
    print("Polynomial Regression - R^2: ", r2_poly)

    plt.plot(yavg_test, 'bo', label='Real Observations')
    # Plot the predicted values
    plt.plot(yavg_pred_poly, 'ro', label='Predicted Values')
    # Add a title to the plot
    plt.title('Poly Model')
    # Create polynomial features (you can choose the degree)
    degree = 2  # You can experiment with different degrees
    poly_features = PolynomialFeatures(degree=degree)
    x_train_poly = poly_features.fit_transform(x_train_nonovelty)
    x_test_poly = poly_features.transform(x_test_nonovelty)
    # Fit the polynomial regression model
    poly_regression_model = LinearRegression()
    poly_regression_model.fit(x_train_poly, yavg_train)

    # Predict on the test data
    yavg_pred_poly2 = poly_regression_model.predict(x_test_poly)

    # Evaluation
    mse_poly = mean_squared_error(yavg_test, yavg_pred_poly)
    r2_poly = r2_score(yavg_test, yavg_pred_poly)

    print("Polynomial Regression - MSE: ", mse_poly)
    print("Polynomial Regression - R^2: ", r2_poly)
    return mse_poly

"""## <font color='green'> Channels

### <font color='blue'> Subj 0
"""

mse_poly1 = svr_model(x_train1, x_test1, yavg_train1, yavg_test1, x_train_nonovelty1, x_test_nonovelty1)

"""### <font color='blue'> Subj 1"""

msepoly2 = svr_model(x_train2, x_test2, yavg_train2, yavg_test2, x_train_nonovelty2, x_test_nonovelty2)

"""### <font color='blue'> Subj 2"""

msepoly3 = svr_model(x_train3, x_test3, yavg_train3, yavg_test3, x_train_nonovelty3, x_test_nonovelty3)

"""### <font color='blue'> Subj 3"""

msepoly4 = svr_model(x_train4, x_test4, yavg_train4, yavg_test4, x_train_nonovelty4, x_test_nonovelty4)

"""### <font color='blue'> Subj 5"""

msepoly6 = svr_model(x_train6, x_test6, yavg_train6, yavg_test6, x_train_nonovelty6, x_test_nonovelty6)